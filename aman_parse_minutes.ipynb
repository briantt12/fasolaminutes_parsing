{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spacy Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FuzzyWuzzy Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "matched_word: Alice Hockstetler     score: 94\n",
      "score condition:  True\n",
      "identical condition True\n",
      "Alice Hochstetler :    ('Alice Hockstetler', True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "failed = []\n",
    "# Load data\n",
    "df = pd.read_csv('passed_names_1000.csv')\n",
    "\n",
    "# Extract names that start with 'Jess'\n",
    "passed_names = set(df['Passed Words'])\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_initials(name):\n",
    "    \"\"\"Convert the second name to an initial if there are more than two words.\"\"\"\n",
    "    words = name.split()\n",
    "    if len(words) >= 3:  # If there's a middle name or extra names\n",
    "        return f\"{words[0]} {words[1][0]}. {words[-1]}\"  # Convert only the second word to an initial\n",
    "    if len(words) == 2:\n",
    "        return name  # Keep first and last name as is\n",
    "    return name  # Return as is if single word\n",
    "\n",
    "def ner_check_person_is_name(text):\n",
    "    \"\"\"Check if a word is a person's name using spaCy NER and POS tagging.\"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return True, ent.text  # Detected as a named entity (PERSON)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\":\n",
    "            return True, token.text  # Detected as a proper noun\n",
    "\n",
    "    return False, \"fail:\" + text  # Neither detected\n",
    "\n",
    "\n",
    "def is_name_test(word,confidence):\n",
    "    \n",
    "        \n",
    "    converted_name = convert_to_initials(word)\n",
    "    \n",
    "\n",
    "    # Try fuzzy matching on double names\n",
    "    match = process.extractOne(converted_name, passed_names, scorer=fuzz.ratio)\n",
    "    if match:\n",
    "        matched_word, score = match\n",
    "        print('matched_word:',matched_word,'    score:',score)\n",
    "        print('score condition: ',score >= confidence)\n",
    "        print('identical condition', converted_name not in passed_names)\n",
    "        if score >= confidence and converted_name not in passed_names:\n",
    "            \n",
    "            return True, matched_word\n",
    "    \n",
    "    \n",
    "    return False, \"fail:\" + word  # Ensure a tuple is always returned\n",
    "\n",
    "def clean_ner(name):\n",
    "    \"\"\"Process names and avoid redundant spaCy checks.\"\"\"\n",
    "    name = name.strip()\n",
    "    is_name_flag, returned_name = is_name_test(name, 80)\n",
    "    return returned_name, is_name_flag  # Return the matched name and flag\n",
    "\n",
    "print(len(passed_names))\n",
    "name = 'Alice Hochstetler'\n",
    "print(name,':   ',clean_ner(name))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing Minutes with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 448\u001b[0m\n\u001b[1;32m    447\u001b[0m db \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mopen_db()\n\u001b[0;32m--> 448\u001b[0m \u001b[43mclear_minutes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m parse_all_minutes(db)\n",
      "Cell \u001b[0;32mIn[4], line 438\u001b[0m, in \u001b[0;36mclear_minutes\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    437\u001b[0m curs \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m--> 438\u001b[0m \u001b[43mcurs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDELETE FROM leaders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m curs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDELETE FROM song_leader_joins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOperationalError\u001b[0m: database is locked",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "import pandas as pd\n",
    "import re\n",
    "import util\n",
    "import spacy\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "batch = 23000\n",
    "confidence = 85\n",
    "\n",
    "times=[]\n",
    "names_count = []\n",
    "# Caching sets\n",
    "cached_non_name_words = set()\n",
    "passed_names = set()  # Store full names for fuzzy matching\n",
    "matched = set()\n",
    "final_words = set()\n",
    "failed = set()\n",
    "fuzzyCount = 0\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "def convert_to_initials(name):\n",
    "    \"\"\"Convert the second name to an initial if there are more than two words.\"\"\"\n",
    "    words = name.split()\n",
    "    if len(words) >= 3:  # If there's a middle name or extra names\n",
    "        return f\"{words[0]} {words[1][0]}. {words[-1]}\"  # Convert only the second word to an initial\n",
    "    if len(words) == 2:\n",
    "        return name  # Keep first and last name as is\n",
    "    return name  # Return as is if single word\n",
    "\n",
    "def ner_check_person_is_name(text):\n",
    "    \"\"\"Check if a word is a person's name using spaCy NER and POS tagging.\"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            return True, ent.text  # Detected as a named entity (PERSON)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"PROPN\":\n",
    "            return True, token.text  # Detected as a proper noun\n",
    "\n",
    "    return False, \"fail:\" + text  # Neither detected\n",
    "\n",
    "\n",
    "def is_name(word,confidence):\n",
    "    global start_time, fuzzyCount\n",
    "    if(len(passed_names)% batch == 0 and batch < 22000):\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        final_words.update(passed_names)\n",
    "        print('passed name count:',len(final_words))\n",
    "        pd.DataFrame({\"Passed Words\": sorted(list(final_words))}).to_csv(\"passed_names_\"+str(batch)+\".csv\", index=False)\n",
    "        pd.DataFrame({\"Matched Words\": sorted(list(matched))}).to_csv(\"matched_names_\"+str(batch)+\".csv\", index=False)\n",
    "        times.append(elapsed_time/60)\n",
    "        names_count.append(len(final_words))\n",
    "        passed_names.clear()\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))  # Set figure size\n",
    "        plt.plot(times,names_count, marker='o', linestyle='-', color='b', label=\"Processing Time\")\n",
    "        plt.ylabel(\"Number of Items in final_words\")\n",
    "        plt.xlabel(\"Time Taken (Min)\")\n",
    "        plt.title(\"Number of Passed Names vs Time\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.savefig(\"time_count_\"+str(batch)+\".png\")  # Saves as a PNG file\n",
    "        plt.close()\n",
    "    else:\n",
    "        if(len(passed_names)> 20000):\n",
    "            \n",
    "            final_words.update(passed_names)\n",
    "            pd.DataFrame({\"Passed Words\": sorted(list(final_words))}).to_csv(\"passed_names_full.csv\", index=False)\n",
    "            pd.DataFrame({\"Matched Words\": sorted(list(matched))}).to_csv(\"matched_names_full.csv\", index=False)\n",
    "        \n",
    "    converted_name = convert_to_initials(word)\n",
    "    \n",
    "    if converted_name in passed_names:\n",
    "        return True, converted_name  # Match found in double_names\n",
    "\n",
    "    if converted_name in cached_non_name_words:\n",
    "        return False, \"fail:\" + word  # Cached as non-name\n",
    "\n",
    "\n",
    "    # Try fuzzy matching on double names\n",
    "    match = process.extractOne(converted_name, passed_names, scorer=fuzz.ratio)\n",
    "    if match:\n",
    "        matched_word, score = match\n",
    "        if score >= confidence and converted_name not in passed_names:\n",
    "            fuzzyCount+=1\n",
    "            matched.add(matched_word+': '+str(score))\n",
    "            return True, matched_word\n",
    "            \n",
    "    # if not found in history, check NER\n",
    "    if ner_check_person_is_name(converted_name):\n",
    "        passed_names.add(converted_name)\n",
    "        return True, converted_name\n",
    "        \n",
    "    cached_non_name_words.add(converted_name)  # Cache as non-name\n",
    "    \n",
    "    return False, \"fail:\" + word  # Ensure a tuple is always returned\n",
    "\n",
    "def clean_ner(name):\n",
    "    \"\"\"Process names and avoid redundant spaCy checks.\"\"\"\n",
    "    name = name.strip()\n",
    "    is_name_flag, returned_name = is_name(name, 80)\n",
    "    return returned_name, is_name_flag  # Return the matched name and flag\n",
    "\n",
    "\n",
    "bad_words = [\n",
    "    'Chairman',\n",
    "    'Chairperson',\n",
    "    'Chairwoman',\n",
    "    'Chairmen',\n",
    "    'Chair',\n",
    "    'Chairlady',\n",
    "    'Chairpersons',\n",
    "    'Chairs',\n",
    "    'Co-Chair',\n",
    "    'Co-Chairs',\n",
    "    'Co-Chairmen',\n",
    "    'Co-Chairperson',\n",
    "    'Co-chair',\n",
    "    'Co-chairs',\n",
    "    'Singing',\n",
    "    'Secretary',\n",
    "    'Secretaries',\n",
    "    'Treasurer',\n",
    "    'Treasurers',\n",
    "    'Director',\n",
    "    'Committee',\n",
    "    'Committees',\n",
    "    'Convention',\n",
    "    'Sacred',\n",
    "    'Musical',\n",
    "    'Methodist',\n",
    "    'Baptist',\n",
    "    'Episcopal',\n",
    "    'Anglican',\n",
    "    'Mennonite',\n",
    "    'Catholic',\n",
    "    'Pastor',\n",
    "    'Minister',\n",
    "    'Ministry',\n",
    "    'National',\n",
    "    'Library',\n",
    "    'Shape',\n",
    "    'Note',\n",
    "    'State',\n",
    "    'Sacra',\n",
    "    'United',\n",
    "    'Memorial',\n",
    "    'Alabama',\n",
    "    'Mississippi',\n",
    "    'Arrangement',\n",
    "    'Arrangements',\n",
    "    'Arranging',\n",
    "    'College',\n",
    "    'University',\n",
    "    'Courthouse',\n",
    "    'Meetinghouse',\n",
    "    'Meeting House'\n",
    "    'Friends',\n",
    "    'Seminary',\n",
    "    'Cemetary',\n",
    "    'SHMHA',\n",
    "    'Seek',\n",
    "    'President',\n",
    "    'Vice',\n",
    "    'After',\n",
    "    'Then',\n",
    "    'Academy',\n",
    "    'Officers',\n",
    "    'Chaplain',\n",
    "    'Fasola',\n",
    "    'FaSoLa',\n",
    "    'Southern',\n",
    "    'Western',\n",
    "    'Northwestern',\n",
    "    'North',\n",
    "    'Pacific',\n",
    "    'Northern',\n",
    "    'International',\n",
    "    'Center',\n",
    "    'African',\n",
    "    'American',\n",
    "    'School',\n",
    "    'Elementary',\n",
    "    'Highway',\n",
    "    'Outgoing',\n",
    "    'Recreation',\n",
    "    'City',\n",
    "    'County',\n",
    "    'Avenue',\n",
    "    'Public',\n",
    "    'Publishing',\n",
    "    'Primitive',\n",
    "    'Mountain',\n",
    "    'Annual',\n",
    "    'Department',\n",
    "    'Presbyterian',\n",
    "    'Conference',\n",
    "    'Railroad',\n",
    "    'Society',\n",
    "    'Historical',\n",
    "    'Association',\n",
    "    'Professor',\n",
    "    'Associate',\n",
    "    'Municipal',\n",
    "    'Building',\n",
    "    'Labor',\n",
    "    'County',\n",
    "    'Line',\n",
    "    'Elder',\n",
    "    'Resolutions',\n",
    "    'Father',\n",
    "    'Moderator']\n",
    "\n",
    "\n",
    "non_denson = [\n",
    "    'ACH',\n",
    "    'AH',\n",
    "    'AV',\n",
    "    'CB',\n",
    "    'CH',\n",
    "    'EH\\s1',\n",
    "    'EH\\s2',\n",
    "    'EH1',\n",
    "    'EH2',\n",
    "    'SoH',\n",
    "    'GH',\n",
    "    'HS',\n",
    "    'ICH',\n",
    "    'KsH',\n",
    "    'KH',\n",
    "    'LD',\n",
    "    'MH',\n",
    "    'NH',\n",
    "    'NHC',\n",
    "    'OSH',\n",
    "    'ShH',\n",
    "    'ScH',\n",
    "    'WB']\n",
    "\n",
    "\n",
    "def build_bad_words():\n",
    "    ss = ''\n",
    "    for s in bad_words:\n",
    "        ss += s + '[\\.\\s,’]+|'\n",
    "    ss = ss[:-1]\n",
    "    return ss\n",
    "\n",
    "\n",
    "def build_non_denson():\n",
    "    ss = ''\n",
    "    for s in non_denson:\n",
    "        ss += r'\\(' + s + r'\\)|'\n",
    "    ss = ss[:-1]\n",
    "    return ss\n",
    "\n",
    "\n",
    "def parse_minutes(s, debug_print=False):\n",
    "    session_count = 0\n",
    "    sessions = re.split('RECESS|LUNCH',s)\n",
    "    d = []\n",
    "    for session in sessions:\n",
    "        session_count += 1\n",
    "\n",
    "        # name_pattern = re.compile('(?<=Chairman\\s)[A-Z]\\.\\s[A-Z]\\.\\s[A-Z]\\w+|[A-Z]\\.\\s[A-Z]\\.\\s[A-Z]\\w+|(?<=Chairman\\s)[A-Z][\\w]*?\\s[A-Z][\\w]*?\\s[A-Z]\\w+|(?<=Chairman\\s)[A-Z][\\w]*?\\s[A-Z]\\w+|[A-Z][\\w]*?\\s[A-Z][\\w]*?\\s[A-Z]\\w+|[A-Z][\\w]*?\\s[A-Z]\\w+');\n",
    "        name_pattern = re.compile(r'''\n",
    "            (\\A|(?<=\\s))\n",
    "            ((?!''' + build_bad_words() + r''')\n",
    "            (?<!for\\s)\n",
    "            (\n",
    "                # Start with upper case...\n",
    "                [A-Z\\u00C0-\\u024F] |\n",
    "                # ...or lower case followed by a string that has upper case\n",
    "                [a-z](?=[\\u00C0-\\u024F\\w’]*[A-Z\\u00C0-\\u024F])\n",
    "            )\n",
    "            ([\\u00C0-\\u024F\\w’-]+|\\.\\s|\\.)\\s?|van\\sden\\s|Van\\sden\\s|van\\sDen\\s){2,5}\n",
    "        ''', re.UNICODE | re.VERBOSE)\n",
    "        # pagenum_pattern = re.compile('[\\[\\{/](\\d{2,3}[tb]?)[\\]\\}]')\n",
    "        pagenum_pattern = re.compile(r'[\\[\\{/\\s](\\d{2,3}[tb]?)([\\]\\}\\s]|$)(?!' + build_non_denson() + r')')\n",
    "\n",
    "        dd = []\n",
    "        leaders = re.split(r'\\v|called to order|\\:\\s|(?<=[^\\.][^A-Z\\]\\}])\\.(\\s|\\Z)|(?<=[\\]\\}”\\)])[;\\.\\:]|;', session)  #double quotes!\n",
    "        for chunk in leaders:\n",
    "            if chunk and (len(chunk) > 2):\n",
    "                #if debug_print: print(chunk)\n",
    "                songs = re.finditer(pagenum_pattern, chunk)\n",
    "                first_song = None\n",
    "                for song in songs:\n",
    "                    if not first_song:\n",
    "                        first_song = song\n",
    "                    pagenum = song.group(1)\n",
    "                    # print pagenum\n",
    "                    leaders = re.finditer(name_pattern, chunk)\n",
    "                    for leader in leaders:\n",
    "                        if leader.end() <= first_song.start()+1:\n",
    "                            name = leader.group(0)\n",
    "                            name = name.strip() # TODO: should be able to incorporate this into regex......\n",
    "\n",
    "                            name = clean_ner(name)[0]\n",
    "\n",
    "                            dd.append({'name': name, 'song': pagenum})\n",
    "                            if debug_print: print('***name: ' + name + '\\tsong: ' + pagenum)\n",
    "                        # else:\n",
    "                            # print \"%d %d\"%(leader.end(), first_song.start())\n",
    "                if debug_print: print(\"---chunk----------\")\n",
    "\n",
    "        d.append({'session': session_count, 'leaders': dd})\n",
    "        # print \"---session----------\"\n",
    "    # print d\n",
    "    return d\n",
    "\n",
    "LEADERS = {} # leader -> id\n",
    "SONGS = {}   # page -> id\n",
    "ALIASES = {} # alias -> name\n",
    "INVALID = set()\n",
    "def insert_minutes(conn, d, minutes_id, debug_print=False):\n",
    "\n",
    "    curs = conn.cursor()\n",
    "    # Seed dicts\n",
    "    if not SONGS:\n",
    "        for (id, page) in curs.execute(\"SELECT id, PageNum FROM songs\"):\n",
    "            SONGS[page] = id\n",
    "        for (name, alias) in curs.execute(\"SELECT name, alias FROM leader_name_aliases\"):\n",
    "            ALIASES[alias] = ALIASES.get(alias, name) # don't overwrite existing\n",
    "        for (name,) in curs.execute(\"SELECT name FROM leader_name_invalid\"):\n",
    "            INVALID.add(name)\n",
    "\n",
    "    for session in d:\n",
    "        for leader in session['leaders']:\n",
    "\n",
    "            #get song_id\n",
    "            song_id = SONGS.get(leader['song'])\n",
    "            if not song_id:\n",
    "                if leader['song'][-1:] == 't' or leader['song'][-1:] == 'b':\n",
    "                    #check for song without \"t\" or \"b\"\n",
    "                    song_id = SONGS.get(leader['song'][0:-1])\n",
    "                else:\n",
    "                    #check for song on \"top\"\n",
    "                    song_id = SONGS.get(leader['song']+'t')\n",
    "                SONGS[leader['song']] = song_id # memoize this result\n",
    "            if not song_id:\n",
    "                print(leader)\n",
    "                print(\"\\tno song id! %s\"%(leader['song']))\n",
    "                continue\n",
    "\n",
    "            #find leader by name if exists, create if not\n",
    "            name = leader['name']\n",
    "\n",
    "            if name in INVALID:\n",
    "                if debug_print: print(\"invalid name! %s\" % (name))\n",
    "                continue\n",
    "\n",
    "            real_name = ALIASES.get(name)\n",
    "            if real_name:\n",
    "                if debug_print: print(\"replacing %s with %s\" % (name, real_name))\n",
    "                name = real_name\n",
    "\n",
    "            if name == '?':\n",
    "                # marked as a \"bad\" name in the alias table so let's just ignore this altogether\n",
    "                continue\n",
    "\n",
    "            leader_id = LEADERS.get(name)\n",
    "            if not leader_id:\n",
    "                curs.execute(\"INSERT INTO leaders (name) VALUES (?)\", [name])\n",
    "                leader_id = curs.lastrowid\n",
    "                curs.execute(\"UPDATE leader_name_aliases SET leader_id=? WHERE name=?\", [leader_id, name])\n",
    "                LEADERS[name] = leader_id\n",
    "\n",
    "            if song_id and leader_id and minutes_id:\n",
    "                curs.execute(\"INSERT INTO song_leader_joins (song_id, leader_id, minutes_id) VALUES (?,?,?)\", (song_id, leader_id, minutes_id))\n",
    "            else:\n",
    "                print(\"problem?! %d %d %d\" % (song_id, leader_id, minutes_id))\n",
    "\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def parse_all_minutes(conn):\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    # 3928 - camp fasola 2012\n",
    "    # 3542 - ireland\n",
    "    curs.execute(\"SELECT Minutes, Name, Date, id, isDenson, isVirtual FROM minutes\")\n",
    "    rows = curs.fetchall()\n",
    "    for row in rows:\n",
    "\n",
    "        if row[4] == 0 or row[5] == 1:\n",
    "            continue\n",
    "\n",
    "        print(\"%s on %s\" % (row[1], row[2]))\n",
    "        \n",
    "            \n",
    "\n",
    "        s = row[0]\n",
    "        d = parse_minutes(s)\n",
    "\n",
    "        minutes_id = row[3]\n",
    "        insert_minutes(conn, d, minutes_id)\n",
    "\n",
    "    conn.commit()\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def parse_minutes_by_id(conn, minutes_id):\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    # 3928 - camp fasola 2012\n",
    "    # 3542 - ireland\n",
    "    curs.execute(\"SELECT Minutes, Name, Date, id, isDenson FROM minutes WHERE id=?\", [minutes_id])\n",
    "    rows = curs.fetchall()\n",
    "    for row in rows:\n",
    "\n",
    "        if row[4] == 0:\n",
    "            continue\n",
    "\n",
    "        print(\"%s on %s\"%(row[1],row[2]))\n",
    "\n",
    "        s = row[0]\n",
    "        d = parse_minutes(s)\n",
    "\n",
    "        minutes_id = row[3]\n",
    "        insert_minutes(conn, d, minutes_id)\n",
    "        conn.commit()\n",
    "\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def clear_minutes(conn):\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"DELETE FROM leaders\")\n",
    "    curs.execute(\"DELETE FROM song_leader_joins\")\n",
    "    curs.execute(\"DELETE FROM sqlite_sequence WHERE name='leaders'\")\n",
    "    curs.execute(\"DELETE FROM sqlite_sequence WHERE name='song_leader_joins'\")\n",
    "    conn.commit()\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = util.open_db()\n",
    "    clear_minutes(db)\n",
    "    parse_all_minutes(db)\n",
    "    pd.DataFrame({\"Passed Words\": sorted(list(final_words))}).to_csv(\"passed_names.csv\", index=False)\n",
    "    print(\"passed name count:\",len(final_words))\n",
    "\n",
    "\n",
    "    # parse_minutes_by_id(db, 5165)\n",
    "    db.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
