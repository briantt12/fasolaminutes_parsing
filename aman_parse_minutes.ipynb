{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcheck_ner\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreverends\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m, in \u001b[0;36mcheck_ner\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_ner\u001b[39m(text):\n\u001b[0;32m----> 5\u001b[0m     nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# loading pre-trained English Model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     processed_text \u001b[38;5;241m=\u001b[39m nlp(text) \u001b[38;5;66;03m# process text\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m processed_text\u001b[38;5;241m.\u001b[39ment:\n",
      "File \u001b[0;32m~/anaconda/envs/spacy_env/lib/python3.9/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda/envs/spacy_env/lib/python3.9/site-packages/spacy/util.py:471\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "def check_ner(text):\n",
    "    nlp = spacy.load(\"en\") # loading pre-trained English Model\n",
    "    processed_text = nlp(text) # process text\n",
    "    for ent in processed_text.ent:\n",
    "        if ent.label_ == \"Person\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "print(check_ner(\"reverends\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spacy Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Brian Sam Williams', True)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "ner = spacy.load('en_core_web_sm')\n",
    "def clean_ner(text):\n",
    "    processed_text = ner(text)\n",
    "    if processed_text.ents:\n",
    "        return processed_text.ents[0].text, True\n",
    "\n",
    "list = []\n",
    "name = 'Reverend Brian Sam Williams'\n",
    "\n",
    "bad_words = [\n",
    "    'Chairman',\n",
    "    'Chairperson',\n",
    "    'Chairwoman',\n",
    "    'Chairmen',\n",
    "    'Chair',\n",
    "    'Chairlady',\n",
    "    'Chairpersons',\n",
    "    'Chairs',\n",
    "    'Co-Chair',\n",
    "    'Co-Chairs',\n",
    "    'Co-Chairmen',\n",
    "    'Co-Chairperson',\n",
    "    'Co-chair',\n",
    "    'Co-chairs',\n",
    "    'Singing',\n",
    "    'Secretary',\n",
    "    'Secretaries',\n",
    "    'Treasurer',\n",
    "    'Treasurers',\n",
    "    'Director',\n",
    "    'Committee',\n",
    "    'Committees',\n",
    "    'Convention',\n",
    "    'Sacred',\n",
    "    'Musical',\n",
    "    'Methodist',\n",
    "    'Baptist',\n",
    "    'Episcopal',\n",
    "    'Anglican',\n",
    "    'Mennonite',\n",
    "    'Catholic',\n",
    "    'Pastor',\n",
    "    'Minister',\n",
    "    'Ministry',\n",
    "    'National',\n",
    "    'Library',\n",
    "    'Shape',\n",
    "    'Note',\n",
    "    'State',\n",
    "    'Sacra',\n",
    "    'United',\n",
    "    'Memorial',\n",
    "    'Alabama',\n",
    "    'Mississippi',\n",
    "    'Arrangement',\n",
    "    'Arrangements',\n",
    "    'Arranging',\n",
    "    'College',\n",
    "    'University',\n",
    "    'Courthouse',\n",
    "    'Meetinghouse',\n",
    "    'Meeting House'\n",
    "    'Friends',\n",
    "    'Seminary',\n",
    "    'Cemetary',\n",
    "    'SHMHA',\n",
    "    'Seek',\n",
    "    'President',\n",
    "    'Vice',\n",
    "    'After',\n",
    "    'Then',\n",
    "    'Academy',\n",
    "    'Officers',\n",
    "    'Chaplain',\n",
    "    'Fasola',\n",
    "    'FaSoLa',\n",
    "    'Southern',\n",
    "    'Western',\n",
    "    'Northwestern',\n",
    "    'North',\n",
    "    'Pacific',\n",
    "    'Northern',\n",
    "    'International',\n",
    "    'Center',\n",
    "    'African',\n",
    "    'American',\n",
    "    'School',\n",
    "    'Elementary',\n",
    "    'Highway',\n",
    "    'Outgoing',\n",
    "    'Recreation',\n",
    "    'City',\n",
    "    'County',\n",
    "    'Avenue',\n",
    "    'Public',\n",
    "    'Publishing',\n",
    "    'Primitive',\n",
    "    'Mountain',\n",
    "    'Annual',\n",
    "    'Department',\n",
    "    'Presbyterian',\n",
    "    'Conference',\n",
    "    'Railroad',\n",
    "    'Society',\n",
    "    'Historical',\n",
    "    'Association',\n",
    "    'Professor',\n",
    "    'Associate',\n",
    "    'Municipal',\n",
    "    'Building',\n",
    "    'Labor',\n",
    "    'County',\n",
    "    'Line',\n",
    "    'Elder',\n",
    "    'Resolutions',\n",
    "    'Father',\n",
    "    'Moderator']\n",
    "\n",
    "for word in bad_words:\n",
    "    example = word+\" \"+name\n",
    "    list.append(example)\n",
    "    \n",
    "\n",
    "print(clean_ner(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chairman Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairperson Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairwoman Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairmen Brian Sam Williams  :  Brian Sam Williams\n",
      "Chair Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairlady Brian Sam Williams  :  Chairlady\n",
      "Chairpersons Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairs Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chair Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chairs Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chairmen Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chairperson Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-chair Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-chairs Brian Sam Williams  :  Brian Sam Williams\n",
      "Singing Brian Sam Williams  :  Brian Sam Williams\n",
      "Secretary Brian Sam Williams  :  Brian Sam Williams\n",
      "Secretaries Brian Sam Williams  :  Brian Sam Williams\n",
      "Treasurer Brian Sam Williams  :  Brian Sam Williams\n",
      "Treasurers Brian Sam Williams  :  Brian Sam Williams\n",
      "Director Brian Sam Williams  :  Brian Sam Williams\n",
      "Committee Brian Sam Williams  :  Brian Sam Williams\n",
      "Committees Brian Sam Williams  :  Brian Sam Williams\n",
      "Convention Brian Sam Williams  :  Brian Sam Williams\n",
      "Sacred Brian Sam Williams  :  Brian Sam Williams\n",
      "Musical Brian Sam Williams  :  Brian Sam Williams\n",
      "Methodist Brian Sam Williams  :  Brian Sam Williams\n",
      "Baptist Brian Sam Williams  :  Brian Sam Williams\n",
      "Episcopal Brian Sam Williams  :  Brian Sam Williams\n",
      "Anglican Brian Sam Williams  :  Brian Sam Williams\n",
      "Mennonite Brian Sam Williams  :  Brian Sam Williams\n",
      "Catholic Brian Sam Williams  :  Brian Sam Williams\n",
      "Pastor Brian Sam Williams  :  Brian Sam Williams\n",
      "Minister Brian Sam Williams  :  Brian Sam Williams\n",
      "Ministry Brian Sam Williams  :  Brian Sam Williams\n",
      "National Brian Sam Williams  :  Brian Sam Williams\n",
      "Library Brian Sam Williams  :  Brian Sam Williams\n",
      "Shape Brian Sam Williams  :  Brian Sam Williams\n",
      "Note Brian Sam Williams  :  Brian Sam Williams\n",
      "State Brian Sam Williams  :  Brian Sam Williams\n",
      "Sacra Brian Sam Williams  :  Brian Sam Williams\n",
      "United Brian Sam Williams  :  Brian Sam Williams\n",
      "Memorial Brian Sam Williams  :  Brian Sam Williams\n",
      "Alabama Brian Sam Williams  :  Brian Sam Williams\n",
      "Mississippi Brian Sam Williams  :  Brian Sam Williams\n",
      "Arrangement Brian Sam Williams  :  Brian Sam Williams\n",
      "Arrangements Brian Sam Williams  :  Brian Sam Williams\n",
      "Arranging Brian Sam Williams  :  Brian Sam Williams\n",
      "College Brian Sam Williams  :  Brian Sam Williams\n",
      "University Brian Sam Williams  :  Brian Sam Williams\n",
      "Courthouse Brian Sam Williams  :  Brian Sam Williams\n",
      "Meetinghouse Brian Sam Williams  :  Brian Sam Williams\n",
      "Meeting HouseFriends Brian Sam Williams  :  HouseFriends Brian Sam Williams\n",
      "Seminary Brian Sam Williams  :  Brian Sam Williams\n",
      "Cemetary Brian Sam Williams  :  Brian Sam Williams\n",
      "SHMHA Brian Sam Williams  :  Brian Sam Williams\n",
      "Seek Brian Sam Williams  :  Brian Sam Williams\n",
      "President Brian Sam Williams  :  Brian Sam Williams\n",
      "Vice Brian Sam Williams  :  Brian Sam Williams\n",
      "After Brian Sam Williams  :  Brian Sam Williams\n",
      "Then Brian Sam Williams  :  Brian Sam Williams\n",
      "Academy Brian Sam Williams  :  Brian Sam Williams\n",
      "Officers Brian Sam Williams  :  Brian Sam Williams\n",
      "Chaplain Brian Sam Williams  :  Brian Sam Williams\n",
      "Fasola Brian Sam Williams  :  Brian Sam Williams\n",
      "FaSoLa Brian Sam Williams  :  Brian Sam Williams\n",
      "Southern Brian Sam Williams  :  Brian Sam Williams\n",
      "Western Brian Sam Williams  :  Brian Sam Williams\n",
      "Northwestern Brian Sam Williams  :  Brian Sam Williams\n",
      "North Brian Sam Williams  :  Brian Sam Williams\n",
      "Pacific Brian Sam Williams  :  Brian Sam Williams\n",
      "Northern Brian Sam Williams  :  Brian Sam Williams\n",
      "International Brian Sam Williams  :  Brian Sam Williams\n",
      "Center Brian Sam Williams  :  Brian Sam Williams\n",
      "African Brian Sam Williams  :  Brian Sam Williams\n",
      "American Brian Sam Williams  :  Brian Sam Williams\n",
      "School Brian Sam Williams  :  Brian Sam Williams\n",
      "Elementary Brian Sam Williams  :  Brian Sam Williams\n",
      "Highway Brian Sam Williams  :  Brian Sam Williams\n",
      "Outgoing Brian Sam Williams  :  Brian Sam Williams\n",
      "Recreation Brian Sam Williams  :  Brian Sam Williams\n",
      "City Brian Sam Williams  :  Brian Sam Williams\n",
      "County Brian Sam Williams  :  Brian Sam Williams\n",
      "Avenue Brian Sam Williams  :  Brian Sam Williams\n",
      "Public Brian Sam Williams  :  Brian Sam Williams\n",
      "Publishing Brian Sam Williams  :  Brian Sam Williams\n",
      "Primitive Brian Sam Williams  :  Brian Sam Williams\n",
      "Mountain Brian Sam Williams  :  Brian Sam Williams\n",
      "Annual Brian Sam Williams  :  Brian Sam Williams\n",
      "Department Brian Sam Williams  :  Brian Sam Williams\n",
      "Presbyterian Brian Sam Williams  :  Brian Sam Williams\n",
      "Conference Brian Sam Williams  :  Brian Sam Williams\n",
      "Railroad Brian Sam Williams  :  Brian Sam Williams\n",
      "Society Brian Sam Williams  :  Brian Sam Williams\n",
      "Historical Brian Sam Williams  :  Brian Sam Williams\n",
      "Association Brian Sam Williams  :  Brian Sam Williams\n",
      "Professor Brian Sam Williams  :  Brian Sam Williams\n",
      "Associate Brian Sam Williams  :  Brian Sam Williams\n",
      "Municipal Brian Sam Williams  :  Brian Sam Williams\n",
      "Building Brian Sam Williams  :  Brian Sam Williams\n",
      "Labor Brian Sam Williams  :  Brian Sam Williams\n",
      "County Brian Sam Williams  :  Brian Sam Williams\n",
      "Line Brian Sam Williams  :  Brian Sam Williams\n",
      "Elder Brian Sam Williams  :  Brian Sam Williams\n",
      "Resolutions Brian Sam Williams  :  Brian Sam Williams\n",
      "Father Brian Sam Williams  :  Brian Sam Williams\n",
      "Moderator Brian Sam Williams  :  Brian Sam Williams\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "ner = spacy.load(\"en_core_web_sm\")\n",
    "def clean_ner(text):\n",
    "\n",
    "    names = text.split()\n",
    "    \n",
    "    if len(names) >= 3: # under assumption len of 2 is only first and last name\n",
    "        processed_text = ner(names[0])\n",
    "        for ent in processed_text.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                return ent.text, True\n",
    "    return \" \".join(names[1:]), False\n",
    "\n",
    "\n",
    "name = 'Brian Sam Williams'\n",
    "list = []\n",
    "bad_words = [\n",
    "    'Chairman',\n",
    "    'Chairperson',\n",
    "    'Chairwoman',\n",
    "    'Chairmen',\n",
    "    'Chair',\n",
    "    'Chairlady',\n",
    "    'Chairpersons',\n",
    "    'Chairs',\n",
    "    'Co-Chair',\n",
    "    'Co-Chairs',\n",
    "    'Co-Chairmen',\n",
    "    'Co-Chairperson',\n",
    "    'Co-chair',\n",
    "    'Co-chairs',\n",
    "    'Singing',\n",
    "    'Secretary',\n",
    "    'Secretaries',\n",
    "    'Treasurer',\n",
    "    'Treasurers',\n",
    "    'Director',\n",
    "    'Committee',\n",
    "    'Committees',\n",
    "    'Convention',\n",
    "    'Sacred',\n",
    "    'Musical',\n",
    "    'Methodist',\n",
    "    'Baptist',\n",
    "    'Episcopal',\n",
    "    'Anglican',\n",
    "    'Mennonite',\n",
    "    'Catholic',\n",
    "    'Pastor',\n",
    "    'Minister',\n",
    "    'Ministry',\n",
    "    'National',\n",
    "    'Library',\n",
    "    'Shape',\n",
    "    'Note',\n",
    "    'State',\n",
    "    'Sacra',\n",
    "    'United',\n",
    "    'Memorial',\n",
    "    'Alabama',\n",
    "    'Mississippi',\n",
    "    'Arrangement',\n",
    "    'Arrangements',\n",
    "    'Arranging',\n",
    "    'College',\n",
    "    'University',\n",
    "    'Courthouse',\n",
    "    'Meetinghouse',\n",
    "    'Meeting House'\n",
    "    'Friends',\n",
    "    'Seminary',\n",
    "    'Cemetary',\n",
    "    'SHMHA',\n",
    "    'Seek',\n",
    "    'President',\n",
    "    'Vice',\n",
    "    'After',\n",
    "    'Then',\n",
    "    'Academy',\n",
    "    'Officers',\n",
    "    'Chaplain',\n",
    "    'Fasola',\n",
    "    'FaSoLa',\n",
    "    'Southern',\n",
    "    'Western',\n",
    "    'Northwestern',\n",
    "    'North',\n",
    "    'Pacific',\n",
    "    'Northern',\n",
    "    'International',\n",
    "    'Center',\n",
    "    'African',\n",
    "    'American',\n",
    "    'School',\n",
    "    'Elementary',\n",
    "    'Highway',\n",
    "    'Outgoing',\n",
    "    'Recreation',\n",
    "    'City',\n",
    "    'County',\n",
    "    'Avenue',\n",
    "    'Public',\n",
    "    'Publishing',\n",
    "    'Primitive',\n",
    "    'Mountain',\n",
    "    'Annual',\n",
    "    'Department',\n",
    "    'Presbyterian',\n",
    "    'Conference',\n",
    "    'Railroad',\n",
    "    'Society',\n",
    "    'Historical',\n",
    "    'Association',\n",
    "    'Professor',\n",
    "    'Associate',\n",
    "    'Municipal',\n",
    "    'Building',\n",
    "    'Labor',\n",
    "    'County',\n",
    "    'Line',\n",
    "    'Elder',\n",
    "    'Resolutions',\n",
    "    'Father',\n",
    "    'Moderator']\n",
    "\n",
    "for word in bad_words:\n",
    "    example = word+\" \"+name\n",
    "    list.append(example)\n",
    "\n",
    "    print(example,\" : \",clean_ner(example)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FuzzyWuzzy Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jesse P. Karlsberg J.P Karlsberg\n",
      "fuzz.ratio:  77\n",
      "fuzz.WRatio:  87\n",
      "\n",
      "Billy Williams, Doyle Williams:\n",
      "fuzz.ratio:  71\n",
      "fuzz.WRatio:  71\n",
      "\n",
      "Billy Williams, Corene White\n",
      "fuzz.ratio:  23\n",
      "fuzz.WRatio:  23\n",
      "Brian Williams, Brian Williams\n",
      "fuzz.ratio:  80\n",
      "fuzz.WRatio:  90\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "print('Jesse P. Karlsberg', 'J.P Karlsberg')\n",
    "print('fuzz.ratio: ',fuzz.ratio('Jesse P. Karlsberg', 'J.P Karlsberg')) #\n",
    "print('fuzz.WRatio: ',fuzz.WRatio('Jesse P. Karlsberg', 'J.P Karlsberg')) # handles lower and upper cases and some other parameters too\n",
    "\n",
    "print()\n",
    "print('Billy Williams,', 'Doyle Williams:')\n",
    "print('fuzz.ratio: ',fuzz.ratio('Billy Williams', 'Doyle Williams')) #\n",
    "print('fuzz.WRatio: ',fuzz.WRatio('Billy Williams', 'Doyle Williams')) # handles lower and upper cases and some other parameters too\n",
    "\n",
    "print()\n",
    "print('Billy Williams,', 'Corene White')\n",
    "print('fuzz.ratio: ',fuzz.ratio('Billy Williams', 'Corene White')) #\n",
    "print('fuzz.WRatio: ',fuzz.WRatio('Billy Williams', 'Corene White')) # handles lower and upper cases and some other parameters too\n",
    "\n",
    "\n",
    "\n",
    "print('Brian Williams,', 'Brian Williams')\n",
    "print('fuzz.ratio: ',fuzz.ratio('Father Brian Williams', 'Brian Williams')) #\n",
    "print('fuzz.WRatio: ',fuzz.WRatio('Father Brian Williams', 'Brian Williams')) # handles lower and upper cases and some other parameters too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing Minutes Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing Minutes with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# encoding: utf-8\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutil\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "import pandas as pd\n",
    "import re\n",
    "import util\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "cached_bad_words = set()  # Cache of confirmed non-names\n",
    "cached_name_words = set()  # Cache of confirmed names\n",
    "\n",
    "def is_name(word):\n",
    "    \"\"\"Check if a word is a name using caching and spaCy.\"\"\"\n",
    "    if word in cached_name_words:\n",
    "        return True\n",
    "    if word in cached_bad_words:\n",
    "        return False\n",
    "\n",
    "    doc = nlp(word)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":  \n",
    "            cached_name_words.add(word)\n",
    "            return True\n",
    "\n",
    "    cached_bad_words.add(word)  # Cache non-names\n",
    "    \n",
    "    return False\n",
    "\n",
    "def clean_ner(name):\n",
    "    \"\"\"Process names and avoid redundant spaCy checks.\"\"\"\n",
    "    name = name.strip()\n",
    "    if is_name(name):\n",
    "        return name, True  # Return name and confirmation that it's a name\n",
    "    return name, False\n",
    "\n",
    "bad_words = [\n",
    "    'Chairman',\n",
    "    'Chairperson',\n",
    "    'Chairwoman',\n",
    "    'Chairmen',\n",
    "    'Chair',\n",
    "    'Chairlady',\n",
    "    'Chairpersons',\n",
    "    'Chairs',\n",
    "    'Co-Chair',\n",
    "    'Co-Chairs',\n",
    "    'Co-Chairmen',\n",
    "    'Co-Chairperson',\n",
    "    'Co-chair',\n",
    "    'Co-chairs',\n",
    "    'Singing',\n",
    "    'Secretary',\n",
    "    'Secretaries',\n",
    "    'Treasurer',\n",
    "    'Treasurers',\n",
    "    'Director',\n",
    "    'Committee',\n",
    "    'Committees',\n",
    "    'Convention',\n",
    "    'Sacred',\n",
    "    'Musical',\n",
    "    'Methodist',\n",
    "    'Baptist',\n",
    "    'Episcopal',\n",
    "    'Anglican',\n",
    "    'Mennonite',\n",
    "    'Catholic',\n",
    "    'Pastor',\n",
    "    'Minister',\n",
    "    'Ministry',\n",
    "    'National',\n",
    "    'Library',\n",
    "    'Shape',\n",
    "    'Note',\n",
    "    'State',\n",
    "    'Sacra',\n",
    "    'United',\n",
    "    'Memorial',\n",
    "    'Alabama',\n",
    "    'Mississippi',\n",
    "    'Arrangement',\n",
    "    'Arrangements',\n",
    "    'Arranging',\n",
    "    'College',\n",
    "    'University',\n",
    "    'Courthouse',\n",
    "    'Meetinghouse',\n",
    "    'Meeting House'\n",
    "    'Friends',\n",
    "    'Seminary',\n",
    "    'Cemetary',\n",
    "    'SHMHA',\n",
    "    'Seek',\n",
    "    'President',\n",
    "    'Vice',\n",
    "    'After',\n",
    "    'Then',\n",
    "    'Academy',\n",
    "    'Officers',\n",
    "    'Chaplain',\n",
    "    'Fasola',\n",
    "    'FaSoLa',\n",
    "    'Southern',\n",
    "    'Western',\n",
    "    'Northwestern',\n",
    "    'North',\n",
    "    'Pacific',\n",
    "    'Northern',\n",
    "    'International',\n",
    "    'Center',\n",
    "    'African',\n",
    "    'American',\n",
    "    'School',\n",
    "    'Elementary',\n",
    "    'Highway',\n",
    "    'Outgoing',\n",
    "    'Recreation',\n",
    "    'City',\n",
    "    'County',\n",
    "    'Avenue',\n",
    "    'Public',\n",
    "    'Publishing',\n",
    "    'Primitive',\n",
    "    'Mountain',\n",
    "    'Annual',\n",
    "    'Department',\n",
    "    'Presbyterian',\n",
    "    'Conference',\n",
    "    'Railroad',\n",
    "    'Society',\n",
    "    'Historical',\n",
    "    'Association',\n",
    "    'Professor',\n",
    "    'Associate',\n",
    "    'Municipal',\n",
    "    'Building',\n",
    "    'Labor',\n",
    "    'County',\n",
    "    'Line',\n",
    "    'Elder',\n",
    "    'Resolutions',\n",
    "    'Father',\n",
    "    'Moderator']\n",
    "\n",
    "\n",
    "non_denson = [\n",
    "    'ACH',\n",
    "    'AH',\n",
    "    'AV',\n",
    "    'CB',\n",
    "    'CH',\n",
    "    'EH\\s1',\n",
    "    'EH\\s2',\n",
    "    'EH1',\n",
    "    'EH2',\n",
    "    'SoH',\n",
    "    'GH',\n",
    "    'HS',\n",
    "    'ICH',\n",
    "    'KsH',\n",
    "    'KH',\n",
    "    'LD',\n",
    "    'MH',\n",
    "    'NH',\n",
    "    'NHC',\n",
    "    'OSH',\n",
    "    'ShH',\n",
    "    'ScH',\n",
    "    'WB']\n",
    "\n",
    "\n",
    "def build_bad_words():\n",
    "    ss = ''\n",
    "    for s in bad_words:\n",
    "        ss += s + '[\\.\\s,’]+|'\n",
    "    ss = ss[:-1]\n",
    "    return ss\n",
    "\n",
    "\n",
    "def build_non_denson():\n",
    "    ss = ''\n",
    "    for s in non_denson:\n",
    "        ss += r'\\(' + s + r'\\)|'\n",
    "    ss = ss[:-1]\n",
    "    return ss\n",
    "\n",
    "\n",
    "def parse_minutes(s, debug_print=False):\n",
    "    session_count = 0\n",
    "    sessions = re.split('RECESS|LUNCH',s)\n",
    "    d = []\n",
    "    for session in sessions:\n",
    "        session_count += 1\n",
    "\n",
    "        # name_pattern = re.compile('(?<=Chairman\\s)[A-Z]\\.\\s[A-Z]\\.\\s[A-Z]\\w+|[A-Z]\\.\\s[A-Z]\\.\\s[A-Z]\\w+|(?<=Chairman\\s)[A-Z][\\w]*?\\s[A-Z][\\w]*?\\s[A-Z]\\w+|(?<=Chairman\\s)[A-Z][\\w]*?\\s[A-Z]\\w+|[A-Z][\\w]*?\\s[A-Z][\\w]*?\\s[A-Z]\\w+|[A-Z][\\w]*?\\s[A-Z]\\w+');\n",
    "        name_pattern = re.compile(r'''\n",
    "            (\\A|(?<=\\s))\n",
    "            ((?!''' + build_bad_words() + r''')\n",
    "            (?<!for\\s)\n",
    "            (\n",
    "                # Start with upper case...\n",
    "                [A-Z\\u00C0-\\u024F] |\n",
    "                # ...or lower case followed by a string that has upper case\n",
    "                [a-z](?=[\\u00C0-\\u024F\\w’]*[A-Z\\u00C0-\\u024F])\n",
    "            )\n",
    "            ([\\u00C0-\\u024F\\w’-]+|\\.\\s|\\.)\\s?|van\\sden\\s|Van\\sden\\s|van\\sDen\\s){2,5}\n",
    "        ''', re.UNICODE | re.VERBOSE)\n",
    "        # pagenum_pattern = re.compile('[\\[\\{/](\\d{2,3}[tb]?)[\\]\\}]')\n",
    "        pagenum_pattern = re.compile(r'[\\[\\{/\\s](\\d{2,3}[tb]?)([\\]\\}\\s]|$)(?!' + build_non_denson() + r')')\n",
    "\n",
    "        dd = []\n",
    "        leaders = re.split(r'\\v|called to order|\\:\\s|(?<=[^\\.][^A-Z\\]\\}])\\.(\\s|\\Z)|(?<=[\\]\\}”\\)])[;\\.\\:]|;', session)  #double quotes!\n",
    "        for chunk in leaders:\n",
    "            if chunk and (len(chunk) > 2):\n",
    "                if debug_print: print(chunk)\n",
    "                songs = re.finditer(pagenum_pattern, chunk)\n",
    "                first_song = None\n",
    "                for song in songs:\n",
    "                    if not first_song:\n",
    "                        first_song = song\n",
    "                    pagenum = song.group(1)\n",
    "                    # print pagenum\n",
    "                    leaders = re.finditer(name_pattern, chunk)\n",
    "                    for leader in leaders:\n",
    "                        if leader.end() <= first_song.start()+1:\n",
    "                            name = leader.group(0)\n",
    "                            name = name.strip() # TODO: should be able to incorporate this into regex......\n",
    "\n",
    "                            name = clean_ner(name)[0]\n",
    "\n",
    "                            dd.append({'name': name, 'song': pagenum})\n",
    "                            if debug_print: print('***name: ' + name + '\\tsong: ' + pagenum)\n",
    "                        # else:\n",
    "                            # print \"%d %d\"%(leader.end(), first_song.start())\n",
    "                if debug_print: print(\"---chunk----------\")\n",
    "\n",
    "        d.append({'session': session_count, 'leaders': dd})\n",
    "        # print \"---session----------\"\n",
    "    # print d\n",
    "    return d\n",
    "\n",
    "LEADERS = {} # leader -> id\n",
    "SONGS = {}   # page -> id\n",
    "ALIASES = {} # alias -> name\n",
    "INVALID = set()\n",
    "def insert_minutes(conn, d, minutes_id, debug_print=False):\n",
    "\n",
    "    curs = conn.cursor()\n",
    "    # Seed dicts\n",
    "    if not SONGS:\n",
    "        for (id, page) in curs.execute(\"SELECT id, PageNum FROM songs\"):\n",
    "            SONGS[page] = id\n",
    "        for (name, alias) in curs.execute(\"SELECT name, alias FROM leader_name_aliases\"):\n",
    "            ALIASES[alias] = ALIASES.get(alias, name) # don't overwrite existing\n",
    "        for (name,) in curs.execute(\"SELECT name FROM leader_name_invalid\"):\n",
    "            INVALID.add(name)\n",
    "\n",
    "    for session in d:\n",
    "        for leader in session['leaders']:\n",
    "\n",
    "            #get song_id\n",
    "            song_id = SONGS.get(leader['song'])\n",
    "            if not song_id:\n",
    "                if leader['song'][-1:] == 't' or leader['song'][-1:] == 'b':\n",
    "                    #check for song without \"t\" or \"b\"\n",
    "                    song_id = SONGS.get(leader['song'][0:-1])\n",
    "                else:\n",
    "                    #check for song on \"top\"\n",
    "                    song_id = SONGS.get(leader['song']+'t')\n",
    "                SONGS[leader['song']] = song_id # memoize this result\n",
    "            if not song_id:\n",
    "                print(leader)\n",
    "                print(\"\\tno song id! %s\"%(leader['song']))\n",
    "                continue\n",
    "\n",
    "            #find leader by name if exists, create if not\n",
    "            name = leader['name']\n",
    "\n",
    "            if name in INVALID:\n",
    "                if debug_print: print(\"invalid name! %s\" % (name))\n",
    "                continue\n",
    "\n",
    "            real_name = ALIASES.get(name)\n",
    "            if real_name:\n",
    "                if debug_print: print(\"replacing %s with %s\" % (name, real_name))\n",
    "                name = real_name\n",
    "\n",
    "            if name == '?':\n",
    "                # marked as a \"bad\" name in the alias table so let's just ignore this altogether\n",
    "                continue\n",
    "\n",
    "            leader_id = LEADERS.get(name)\n",
    "            if not leader_id:\n",
    "                curs.execute(\"INSERT INTO leaders (name) VALUES (?)\", [name])\n",
    "                leader_id = curs.lastrowid\n",
    "                curs.execute(\"UPDATE leader_name_aliases SET leader_id=? WHERE name=?\", [leader_id, name])\n",
    "                LEADERS[name] = leader_id\n",
    "\n",
    "            if song_id and leader_id and minutes_id:\n",
    "                curs.execute(\"INSERT INTO song_leader_joins (song_id, leader_id, minutes_id) VALUES (?,?,?)\", (song_id, leader_id, minutes_id))\n",
    "            else:\n",
    "                print(\"problem?! %d %d %d\" % (song_id, leader_id, minutes_id))\n",
    "\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def parse_all_minutes(conn):\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    # 3928 - camp fasola 2012\n",
    "    # 3542 - ireland\n",
    "    curs.execute(\"SELECT Minutes, Name, Date, id, isDenson, isVirtual FROM minutes\")\n",
    "    rows = curs.fetchall()\n",
    "    for row in rows:\n",
    "\n",
    "        if row[4] == 0 or row[5] == 1:\n",
    "            continue\n",
    "\n",
    "        print(\"%s on %s\" % (row[1], row[2]))\n",
    "\n",
    "        s = row[0]\n",
    "        d = parse_minutes(s)\n",
    "\n",
    "        minutes_id = row[3]\n",
    "        insert_minutes(conn, d, minutes_id)\n",
    "\n",
    "    conn.commit()\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def parse_minutes_by_id(conn, minutes_id):\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    # 3928 - camp fasola 2012\n",
    "    # 3542 - ireland\n",
    "    curs.execute(\"SELECT Minutes, Name, Date, id, isDenson FROM minutes WHERE id=?\", [minutes_id])\n",
    "    rows = curs.fetchall()\n",
    "    for row in rows:\n",
    "\n",
    "        if row[4] == 0:\n",
    "            continue\n",
    "\n",
    "        print(\"%s on %s\"%(row[1],row[2]))\n",
    "\n",
    "        s = row[0]\n",
    "        d = parse_minutes(s)\n",
    "\n",
    "        minutes_id = row[3]\n",
    "        insert_minutes(conn, d, minutes_id)\n",
    "        conn.commit()\n",
    "\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def clear_minutes(conn):\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"DELETE FROM leaders\")\n",
    "    curs.execute(\"DELETE FROM song_leader_joins\")\n",
    "    curs.execute(\"DELETE FROM sqlite_sequence WHERE name='leaders'\")\n",
    "    curs.execute(\"DELETE FROM sqlite_sequence WHERE name='song_leader_joins'\")\n",
    "    conn.commit()\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = util.open_db()\n",
    "    clear_minutes(db)\n",
    "    parse_all_minutes(db)\n",
    "    pd.DataFrame({\"Non-Name Words\": list(cached_bad_words)}).to_csv(\"non_names.csv\", index=False)\n",
    "    # parse_minutes_by_id(db, 5165)\n",
    "    db.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
