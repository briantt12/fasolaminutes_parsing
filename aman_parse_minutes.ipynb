{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spacy Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Brian Sam Williams', True)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "ner = spacy.load('en_core_web_sm')\n",
    "def clean_ner(text):\n",
    "    processed_text = ner(text)\n",
    "    if processed_text.ents:\n",
    "        return processed_text.ents[0].text, True\n",
    "\n",
    "list = []\n",
    "name = 'Reverend Brian Sam Williams'\n",
    "\n",
    "bad_words = [\n",
    "    'Chairman',\n",
    "    'Chairperson',\n",
    "    'Chairwoman',\n",
    "    'Chairmen',\n",
    "    'Chair',\n",
    "    'Chairlady',\n",
    "    'Chairpersons',\n",
    "    'Chairs',\n",
    "    'Co-Chair',\n",
    "    'Co-Chairs',\n",
    "    'Co-Chairmen',\n",
    "    'Co-Chairperson',\n",
    "    'Co-chair',\n",
    "    'Co-chairs',\n",
    "    'Singing',\n",
    "    'Secretary',\n",
    "    'Secretaries',\n",
    "    'Treasurer',\n",
    "    'Treasurers',\n",
    "    'Director',\n",
    "    'Committee',\n",
    "    'Committees',\n",
    "    'Convention',\n",
    "    'Sacred',\n",
    "    'Musical',\n",
    "    'Methodist',\n",
    "    'Baptist',\n",
    "    'Episcopal',\n",
    "    'Anglican',\n",
    "    'Mennonite',\n",
    "    'Catholic',\n",
    "    'Pastor',\n",
    "    'Minister',\n",
    "    'Ministry',\n",
    "    'National',\n",
    "    'Library',\n",
    "    'Shape',\n",
    "    'Note',\n",
    "    'State',\n",
    "    'Sacra',\n",
    "    'United',\n",
    "    'Memorial',\n",
    "    'Alabama',\n",
    "    'Mississippi',\n",
    "    'Arrangement',\n",
    "    'Arrangements',\n",
    "    'Arranging',\n",
    "    'College',\n",
    "    'University',\n",
    "    'Courthouse',\n",
    "    'Meetinghouse',\n",
    "    'Meeting House'\n",
    "    'Friends',\n",
    "    'Seminary',\n",
    "    'Cemetary',\n",
    "    'SHMHA',\n",
    "    'Seek',\n",
    "    'President',\n",
    "    'Vice',\n",
    "    'After',\n",
    "    'Then',\n",
    "    'Academy',\n",
    "    'Officers',\n",
    "    'Chaplain',\n",
    "    'Fasola',\n",
    "    'FaSoLa',\n",
    "    'Southern',\n",
    "    'Western',\n",
    "    'Northwestern',\n",
    "    'North',\n",
    "    'Pacific',\n",
    "    'Northern',\n",
    "    'International',\n",
    "    'Center',\n",
    "    'African',\n",
    "    'American',\n",
    "    'School',\n",
    "    'Elementary',\n",
    "    'Highway',\n",
    "    'Outgoing',\n",
    "    'Recreation',\n",
    "    'City',\n",
    "    'County',\n",
    "    'Avenue',\n",
    "    'Public',\n",
    "    'Publishing',\n",
    "    'Primitive',\n",
    "    'Mountain',\n",
    "    'Annual',\n",
    "    'Department',\n",
    "    'Presbyterian',\n",
    "    'Conference',\n",
    "    'Railroad',\n",
    "    'Society',\n",
    "    'Historical',\n",
    "    'Association',\n",
    "    'Professor',\n",
    "    'Associate',\n",
    "    'Municipal',\n",
    "    'Building',\n",
    "    'Labor',\n",
    "    'County',\n",
    "    'Line',\n",
    "    'Elder',\n",
    "    'Resolutions',\n",
    "    'Father',\n",
    "    'Moderator']\n",
    "\n",
    "for word in bad_words:\n",
    "    example = word+\" \"+name\n",
    "    list.append(example)\n",
    "    \n",
    "\n",
    "print(clean_ner(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chairman Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairperson Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairwoman Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairmen Brian Sam Williams  :  Brian Sam Williams\n",
      "Chair Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairlady Brian Sam Williams  :  Chairlady\n",
      "Chairpersons Brian Sam Williams  :  Brian Sam Williams\n",
      "Chairs Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chair Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chairs Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chairmen Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-Chairperson Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-chair Brian Sam Williams  :  Brian Sam Williams\n",
      "Co-chairs Brian Sam Williams  :  Brian Sam Williams\n",
      "Singing Brian Sam Williams  :  Brian Sam Williams\n",
      "Secretary Brian Sam Williams  :  Brian Sam Williams\n",
      "Secretaries Brian Sam Williams  :  Brian Sam Williams\n",
      "Treasurer Brian Sam Williams  :  Brian Sam Williams\n",
      "Treasurers Brian Sam Williams  :  Brian Sam Williams\n",
      "Director Brian Sam Williams  :  Brian Sam Williams\n",
      "Committee Brian Sam Williams  :  Brian Sam Williams\n",
      "Committees Brian Sam Williams  :  Brian Sam Williams\n",
      "Convention Brian Sam Williams  :  Brian Sam Williams\n",
      "Sacred Brian Sam Williams  :  Brian Sam Williams\n",
      "Musical Brian Sam Williams  :  Brian Sam Williams\n",
      "Methodist Brian Sam Williams  :  Brian Sam Williams\n",
      "Baptist Brian Sam Williams  :  Brian Sam Williams\n",
      "Episcopal Brian Sam Williams  :  Brian Sam Williams\n",
      "Anglican Brian Sam Williams  :  Brian Sam Williams\n",
      "Mennonite Brian Sam Williams  :  Brian Sam Williams\n",
      "Catholic Brian Sam Williams  :  Brian Sam Williams\n",
      "Pastor Brian Sam Williams  :  Brian Sam Williams\n",
      "Minister Brian Sam Williams  :  Brian Sam Williams\n",
      "Ministry Brian Sam Williams  :  Brian Sam Williams\n",
      "National Brian Sam Williams  :  Brian Sam Williams\n",
      "Library Brian Sam Williams  :  Brian Sam Williams\n",
      "Shape Brian Sam Williams  :  Brian Sam Williams\n",
      "Note Brian Sam Williams  :  Brian Sam Williams\n",
      "State Brian Sam Williams  :  Brian Sam Williams\n",
      "Sacra Brian Sam Williams  :  Brian Sam Williams\n",
      "United Brian Sam Williams  :  Brian Sam Williams\n",
      "Memorial Brian Sam Williams  :  Brian Sam Williams\n",
      "Alabama Brian Sam Williams  :  Brian Sam Williams\n",
      "Mississippi Brian Sam Williams  :  Brian Sam Williams\n",
      "Arrangement Brian Sam Williams  :  Brian Sam Williams\n",
      "Arrangements Brian Sam Williams  :  Brian Sam Williams\n",
      "Arranging Brian Sam Williams  :  Brian Sam Williams\n",
      "College Brian Sam Williams  :  Brian Sam Williams\n",
      "University Brian Sam Williams  :  Brian Sam Williams\n",
      "Courthouse Brian Sam Williams  :  Brian Sam Williams\n",
      "Meetinghouse Brian Sam Williams  :  Brian Sam Williams\n",
      "Meeting HouseFriends Brian Sam Williams  :  HouseFriends Brian Sam Williams\n",
      "Seminary Brian Sam Williams  :  Brian Sam Williams\n",
      "Cemetary Brian Sam Williams  :  Brian Sam Williams\n",
      "SHMHA Brian Sam Williams  :  Brian Sam Williams\n",
      "Seek Brian Sam Williams  :  Brian Sam Williams\n",
      "President Brian Sam Williams  :  Brian Sam Williams\n",
      "Vice Brian Sam Williams  :  Brian Sam Williams\n",
      "After Brian Sam Williams  :  Brian Sam Williams\n",
      "Then Brian Sam Williams  :  Brian Sam Williams\n",
      "Academy Brian Sam Williams  :  Brian Sam Williams\n",
      "Officers Brian Sam Williams  :  Brian Sam Williams\n",
      "Chaplain Brian Sam Williams  :  Brian Sam Williams\n",
      "Fasola Brian Sam Williams  :  Brian Sam Williams\n",
      "FaSoLa Brian Sam Williams  :  Brian Sam Williams\n",
      "Southern Brian Sam Williams  :  Brian Sam Williams\n",
      "Western Brian Sam Williams  :  Brian Sam Williams\n",
      "Northwestern Brian Sam Williams  :  Brian Sam Williams\n",
      "North Brian Sam Williams  :  Brian Sam Williams\n",
      "Pacific Brian Sam Williams  :  Brian Sam Williams\n",
      "Northern Brian Sam Williams  :  Brian Sam Williams\n",
      "International Brian Sam Williams  :  Brian Sam Williams\n",
      "Center Brian Sam Williams  :  Brian Sam Williams\n",
      "African Brian Sam Williams  :  Brian Sam Williams\n",
      "American Brian Sam Williams  :  Brian Sam Williams\n",
      "School Brian Sam Williams  :  Brian Sam Williams\n",
      "Elementary Brian Sam Williams  :  Brian Sam Williams\n",
      "Highway Brian Sam Williams  :  Brian Sam Williams\n",
      "Outgoing Brian Sam Williams  :  Brian Sam Williams\n",
      "Recreation Brian Sam Williams  :  Brian Sam Williams\n",
      "City Brian Sam Williams  :  Brian Sam Williams\n",
      "County Brian Sam Williams  :  Brian Sam Williams\n",
      "Avenue Brian Sam Williams  :  Brian Sam Williams\n",
      "Public Brian Sam Williams  :  Brian Sam Williams\n",
      "Publishing Brian Sam Williams  :  Brian Sam Williams\n",
      "Primitive Brian Sam Williams  :  Brian Sam Williams\n",
      "Mountain Brian Sam Williams  :  Brian Sam Williams\n",
      "Annual Brian Sam Williams  :  Brian Sam Williams\n",
      "Department Brian Sam Williams  :  Brian Sam Williams\n",
      "Presbyterian Brian Sam Williams  :  Brian Sam Williams\n",
      "Conference Brian Sam Williams  :  Brian Sam Williams\n",
      "Railroad Brian Sam Williams  :  Brian Sam Williams\n",
      "Society Brian Sam Williams  :  Brian Sam Williams\n",
      "Historical Brian Sam Williams  :  Brian Sam Williams\n",
      "Association Brian Sam Williams  :  Brian Sam Williams\n",
      "Professor Brian Sam Williams  :  Brian Sam Williams\n",
      "Associate Brian Sam Williams  :  Brian Sam Williams\n",
      "Municipal Brian Sam Williams  :  Brian Sam Williams\n",
      "Building Brian Sam Williams  :  Brian Sam Williams\n",
      "Labor Brian Sam Williams  :  Brian Sam Williams\n",
      "County Brian Sam Williams  :  Brian Sam Williams\n",
      "Line Brian Sam Williams  :  Brian Sam Williams\n",
      "Elder Brian Sam Williams  :  Brian Sam Williams\n",
      "Resolutions Brian Sam Williams  :  Brian Sam Williams\n",
      "Father Brian Sam Williams  :  Brian Sam Williams\n",
      "Moderator Brian Sam Williams  :  Brian Sam Williams\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "ner = spacy.load(\"en_core_web_sm\")\n",
    "def clean_ner(text):\n",
    "\n",
    "    names = text.split()\n",
    "    \n",
    "    if len(names) >= 3: # under assumption len of 2 is only first and last name\n",
    "        processed_text = ner(names[0])\n",
    "        for ent in processed_text.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                return ent.text, True\n",
    "    return \" \".join(names[1:]), False\n",
    "\n",
    "\n",
    "name = 'Brian Sam Williams'\n",
    "list = []\n",
    "bad_words = [\n",
    "    'Chairman',\n",
    "    'Chairperson',\n",
    "    'Chairwoman',\n",
    "    'Chairmen',\n",
    "    'Chair',\n",
    "    'Chairlady',\n",
    "    'Chairpersons',\n",
    "    'Chairs',\n",
    "    'Co-Chair',\n",
    "    'Co-Chairs',\n",
    "    'Co-Chairmen',\n",
    "    'Co-Chairperson',\n",
    "    'Co-chair',\n",
    "    'Co-chairs',\n",
    "    'Singing',\n",
    "    'Secretary',\n",
    "    'Secretaries',\n",
    "    'Treasurer',\n",
    "    'Treasurers',\n",
    "    'Director',\n",
    "    'Committee',\n",
    "    'Committees',\n",
    "    'Convention',\n",
    "    'Sacred',\n",
    "    'Musical',\n",
    "    'Methodist',\n",
    "    'Baptist',\n",
    "    'Episcopal',\n",
    "    'Anglican',\n",
    "    'Mennonite',\n",
    "    'Catholic',\n",
    "    'Pastor',\n",
    "    'Minister',\n",
    "    'Ministry',\n",
    "    'National',\n",
    "    'Library',\n",
    "    'Shape',\n",
    "    'Note',\n",
    "    'State',\n",
    "    'Sacra',\n",
    "    'United',\n",
    "    'Memorial',\n",
    "    'Alabama',\n",
    "    'Mississippi',\n",
    "    'Arrangement',\n",
    "    'Arrangements',\n",
    "    'Arranging',\n",
    "    'College',\n",
    "    'University',\n",
    "    'Courthouse',\n",
    "    'Meetinghouse',\n",
    "    'Meeting House'\n",
    "    'Friends',\n",
    "    'Seminary',\n",
    "    'Cemetary',\n",
    "    'SHMHA',\n",
    "    'Seek',\n",
    "    'President',\n",
    "    'Vice',\n",
    "    'After',\n",
    "    'Then',\n",
    "    'Academy',\n",
    "    'Officers',\n",
    "    'Chaplain',\n",
    "    'Fasola',\n",
    "    'FaSoLa',\n",
    "    'Southern',\n",
    "    'Western',\n",
    "    'Northwestern',\n",
    "    'North',\n",
    "    'Pacific',\n",
    "    'Northern',\n",
    "    'International',\n",
    "    'Center',\n",
    "    'African',\n",
    "    'American',\n",
    "    'School',\n",
    "    'Elementary',\n",
    "    'Highway',\n",
    "    'Outgoing',\n",
    "    'Recreation',\n",
    "    'City',\n",
    "    'County',\n",
    "    'Avenue',\n",
    "    'Public',\n",
    "    'Publishing',\n",
    "    'Primitive',\n",
    "    'Mountain',\n",
    "    'Annual',\n",
    "    'Department',\n",
    "    'Presbyterian',\n",
    "    'Conference',\n",
    "    'Railroad',\n",
    "    'Society',\n",
    "    'Historical',\n",
    "    'Association',\n",
    "    'Professor',\n",
    "    'Associate',\n",
    "    'Municipal',\n",
    "    'Building',\n",
    "    'Labor',\n",
    "    'County',\n",
    "    'Line',\n",
    "    'Elder',\n",
    "    'Resolutions',\n",
    "    'Father',\n",
    "    'Moderator']\n",
    "\n",
    "for word in bad_words:\n",
    "    example = word+\" \"+name\n",
    "    list.append(example)\n",
    "\n",
    "    print(example,\" : \",clean_ner(example)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FuzzyWuzzy Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jesse P. Karlsberg J.P Karlsberg\n",
      "fuzz.ratio:  73\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "print('Jesse P. Karlsberg', 'J.P Karlsberg')\n",
    "print('fuzz.ratio: ',fuzz.ratio('Jessie Karlsburg', 'Jessie Pearlman-Karlsberg')) #\n",
    "# print('fuzz.WRatio: ',fuzz.WRatio('Jesse P. Karlsberg', 'J.P Karlsberg')) # handles lower and upper cases and some other parameters too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Margo Lanagan\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# def is_name(word):\n",
    "#     \"\"\"Check if a word is a name using caching and spaCy.\"\"\"\n",
    "\n",
    "#     doc = nlp(word)\n",
    "#     for token in doc:\n",
    "#         if token.ent_type_ == \"PERSON\":\n",
    "#             return True\n",
    "#         elif token.pos_ == \"PROPN\":\n",
    "#             return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_name(word):\n",
    "    \"\"\"Check if a word is a name using caching and spaCy.\"\"\"\n",
    "\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PERSON\":\n",
    "            return True\n",
    "        elif token.pos_ == \"PROPN\":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "is_name('Will Dove')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing Minutes with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "database is locked",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 389\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    388\u001b[0m     db \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mopen_db()\n\u001b[1;32m--> 389\u001b[0m     \u001b[43mclear_minutes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m     parse_all_minutes(db)\n\u001b[0;32m    391\u001b[0m     pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName Words\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(cached_name_words))})\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy_names.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[14], line 379\u001b[0m, in \u001b[0;36mclear_minutes\u001b[1;34m(conn)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclear_minutes\u001b[39m(conn):\n\u001b[0;32m    378\u001b[0m     curs \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m--> 379\u001b[0m     \u001b[43mcurs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDELETE FROM leaders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m     curs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDELETE FROM song_leader_joins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    381\u001b[0m     curs\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDELETE FROM sqlite_sequence WHERE name=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaders\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOperationalError\u001b[0m: database is locked"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "import pandas as pd\n",
    "import re\n",
    "import util\n",
    "import spacy\n",
    "from fuzzywuzzy import process\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "cached_non_name_words = set()  # Cache of confirmed non-names\n",
    "cached_name_words = set()  # Cache of confirmed names\n",
    "multi_name_words = set()\n",
    "matched_name = set()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def is_name(word):\n",
    "    \"\"\"Check if a word is a name using caching, fuzzy matching, and spaCy.\"\"\"\n",
    "    if word in cached_name_words:\n",
    "        return True\n",
    "    if word in cached_non_name_words:\n",
    "        return False\n",
    "\n",
    "    # Check if it's a multi-word name (more than 2 words)\n",
    "    if len(word.split()) > 2:  \n",
    "        if cached_name_words:  # Use cached names for fuzzy matching\n",
    "            match, score = process.extractOne(word, cached_name_words)\n",
    "            if score >= 80:  # Adjust threshold as needed\n",
    "                return True  # No need to add again\n",
    "\n",
    "        cached_name_words.add(word)  # Cache multi-word names\n",
    "\n",
    "    # Perform NLP-based name detection\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PERSON\" or token.pos_ == \"PROPN\":\n",
    "            cached_name_words.add(word)\n",
    "            return True\n",
    "\n",
    "    cached_non_name_words.add(word)  # Cache non-names\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_ner(name):\n",
    "    \"\"\"Process names and avoid redundant spaCy checks.\"\"\"\n",
    "    name = name.strip()\n",
    "    if is_name(name):\n",
    "        return name, True  # Return name and confirmation that it's a name\n",
    "    return name, False\n",
    "\n",
    "bad_words = [\n",
    "    'Chairman',\n",
    "    'Chairperson',\n",
    "    'Chairwoman',\n",
    "    'Chairmen',\n",
    "    'Chair',\n",
    "    'Chairlady',\n",
    "    'Chairpersons',\n",
    "    'Chairs',\n",
    "    'Co-Chair',\n",
    "    'Co-Chairs',\n",
    "    'Co-Chairmen',\n",
    "    'Co-Chairperson',\n",
    "    'Co-chair',\n",
    "    'Co-chairs',\n",
    "    'Singing',\n",
    "    'Secretary',\n",
    "    'Secretaries',\n",
    "    'Treasurer',\n",
    "    'Treasurers',\n",
    "    'Director',\n",
    "    'Committee',\n",
    "    'Committees',\n",
    "    'Convention',\n",
    "    'Sacred',\n",
    "    'Musical',\n",
    "    'Methodist',\n",
    "    'Baptist',\n",
    "    'Episcopal',\n",
    "    'Anglican',\n",
    "    'Mennonite',\n",
    "    'Catholic',\n",
    "    'Pastor',\n",
    "    'Minister',\n",
    "    'Ministry',\n",
    "    'National',\n",
    "    'Library',\n",
    "    'Shape',\n",
    "    'Note',\n",
    "    'State',\n",
    "    'Sacra',\n",
    "    'United',\n",
    "    'Memorial',\n",
    "    'Alabama',\n",
    "    'Mississippi',\n",
    "    'Arrangement',\n",
    "    'Arrangements',\n",
    "    'Arranging',\n",
    "    'College',\n",
    "    'University',\n",
    "    'Courthouse',\n",
    "    'Meetinghouse',\n",
    "    'Meeting House'\n",
    "    'Friends',\n",
    "    'Seminary',\n",
    "    'Cemetary',\n",
    "    'SHMHA',\n",
    "    'Seek',\n",
    "    'President',\n",
    "    'Vice',\n",
    "    'After',\n",
    "    'Then',\n",
    "    'Academy',\n",
    "    'Officers',\n",
    "    'Chaplain',\n",
    "    'Fasola',\n",
    "    'FaSoLa',\n",
    "    'Southern',\n",
    "    'Western',\n",
    "    'Northwestern',\n",
    "    'North',\n",
    "    'Pacific',\n",
    "    'Northern',\n",
    "    'International',\n",
    "    'Center',\n",
    "    'African',\n",
    "    'American',\n",
    "    'School',\n",
    "    'Elementary',\n",
    "    'Highway',\n",
    "    'Outgoing',\n",
    "    'Recreation',\n",
    "    'City',\n",
    "    'County',\n",
    "    'Avenue',\n",
    "    'Public',\n",
    "    'Publishing',\n",
    "    'Primitive',\n",
    "    'Mountain',\n",
    "    'Annual',\n",
    "    'Department',\n",
    "    'Presbyterian',\n",
    "    'Conference',\n",
    "    'Railroad',\n",
    "    'Society',\n",
    "    'Historical',\n",
    "    'Association',\n",
    "    'Professor',\n",
    "    'Associate',\n",
    "    'Municipal',\n",
    "    'Building',\n",
    "    'Labor',\n",
    "    'County',\n",
    "    'Line',\n",
    "    'Elder',\n",
    "    'Resolutions',\n",
    "    'Father',\n",
    "    'Moderator']\n",
    "\n",
    "\n",
    "non_denson = [\n",
    "    'ACH',\n",
    "    'AH',\n",
    "    'AV',\n",
    "    'CB',\n",
    "    'CH',\n",
    "    'EH\\s1',\n",
    "    'EH\\s2',\n",
    "    'EH1',\n",
    "    'EH2',\n",
    "    'SoH',\n",
    "    'GH',\n",
    "    'HS',\n",
    "    'ICH',\n",
    "    'KsH',\n",
    "    'KH',\n",
    "    'LD',\n",
    "    'MH',\n",
    "    'NH',\n",
    "    'NHC',\n",
    "    'OSH',\n",
    "    'ShH',\n",
    "    'ScH',\n",
    "    'WB']\n",
    "\n",
    "\n",
    "def build_bad_words():\n",
    "    ss = ''\n",
    "    for s in bad_words:\n",
    "        ss += s + '[\\.\\s,’]+|'\n",
    "    ss = ss[:-1]\n",
    "    return ss\n",
    "\n",
    "\n",
    "def build_non_denson():\n",
    "    ss = ''\n",
    "    for s in non_denson:\n",
    "        ss += r'\\(' + s + r'\\)|'\n",
    "    ss = ss[:-1]\n",
    "    return ss\n",
    "\n",
    "\n",
    "def parse_minutes(s, debug_print=False):\n",
    "    session_count = 0\n",
    "    sessions = re.split('RECESS|LUNCH',s)\n",
    "    d = []\n",
    "    for session in sessions:\n",
    "        session_count += 1\n",
    "\n",
    "        # name_pattern = re.compile('(?<=Chairman\\s)[A-Z]\\.\\s[A-Z]\\.\\s[A-Z]\\w+|[A-Z]\\.\\s[A-Z]\\.\\s[A-Z]\\w+|(?<=Chairman\\s)[A-Z][\\w]*?\\s[A-Z][\\w]*?\\s[A-Z]\\w+|(?<=Chairman\\s)[A-Z][\\w]*?\\s[A-Z]\\w+|[A-Z][\\w]*?\\s[A-Z][\\w]*?\\s[A-Z]\\w+|[A-Z][\\w]*?\\s[A-Z]\\w+');\n",
    "        name_pattern = re.compile(r'''\n",
    "            (\\A|(?<=\\s))\n",
    "            ((?!''' + build_bad_words() + r''')\n",
    "            (?<!for\\s)\n",
    "            (\n",
    "                # Start with upper case...\n",
    "                [A-Z\\u00C0-\\u024F] |\n",
    "                # ...or lower case followed by a string that has upper case\n",
    "                [a-z](?=[\\u00C0-\\u024F\\w’]*[A-Z\\u00C0-\\u024F])\n",
    "            )\n",
    "            ([\\u00C0-\\u024F\\w’-]+|\\.\\s|\\.)\\s?|van\\sden\\s|Van\\sden\\s|van\\sDen\\s){2,5}\n",
    "        ''', re.UNICODE | re.VERBOSE)\n",
    "        # pagenum_pattern = re.compile('[\\[\\{/](\\d{2,3}[tb]?)[\\]\\}]')\n",
    "        pagenum_pattern = re.compile(r'[\\[\\{/\\s](\\d{2,3}[tb]?)([\\]\\}\\s]|$)(?!' + build_non_denson() + r')')\n",
    "\n",
    "        dd = []\n",
    "        leaders = re.split(r'\\v|called to order|\\:\\s|(?<=[^\\.][^A-Z\\]\\}])\\.(\\s|\\Z)|(?<=[\\]\\}”\\)])[;\\.\\:]|;', session)  #double quotes!\n",
    "        for chunk in leaders:\n",
    "            if chunk and (len(chunk) > 2):\n",
    "                if debug_print: print(chunk)\n",
    "                songs = re.finditer(pagenum_pattern, chunk)\n",
    "                first_song = None\n",
    "                for song in songs:\n",
    "                    if not first_song:\n",
    "                        first_song = song\n",
    "                    pagenum = song.group(1)\n",
    "                    # print pagenum\n",
    "                    leaders = re.finditer(name_pattern, chunk)\n",
    "                    for leader in leaders:\n",
    "                        if leader.end() <= first_song.start()+1:\n",
    "                            name = leader.group(0)\n",
    "                            name = name.strip() # TODO: should be able to incorporate this into regex......\n",
    "\n",
    "                            name = clean_ner(name)[0]\n",
    "\n",
    "                            dd.append({'name': name, 'song': pagenum})\n",
    "                            if debug_print: print('***name: ' + name + '\\tsong: ' + pagenum)\n",
    "                        # else:\n",
    "                            # print \"%d %d\"%(leader.end(), first_song.start())\n",
    "                if debug_print: print(\"---chunk----------\")\n",
    "\n",
    "        d.append({'session': session_count, 'leaders': dd})\n",
    "        # print \"---session----------\"\n",
    "    # print d\n",
    "    return d\n",
    "\n",
    "LEADERS = {} # leader -> id\n",
    "SONGS = {}   # page -> id\n",
    "ALIASES = {} # alias -> name\n",
    "INVALID = set()\n",
    "def insert_minutes(conn, d, minutes_id, debug_print=False):\n",
    "\n",
    "    curs = conn.cursor()\n",
    "    # Seed dicts\n",
    "    if not SONGS:\n",
    "        for (id, page) in curs.execute(\"SELECT id, PageNum FROM songs\"):\n",
    "            SONGS[page] = id\n",
    "        for (name, alias) in curs.execute(\"SELECT name, alias FROM leader_name_aliases\"):\n",
    "            ALIASES[alias] = ALIASES.get(alias, name) # don't overwrite existing\n",
    "        for (name,) in curs.execute(\"SELECT name FROM leader_name_invalid\"):\n",
    "            INVALID.add(name)\n",
    "\n",
    "    for session in d:\n",
    "        for leader in session['leaders']:\n",
    "\n",
    "            #get song_id\n",
    "            song_id = SONGS.get(leader['song'])\n",
    "            if not song_id:\n",
    "                if leader['song'][-1:] == 't' or leader['song'][-1:] == 'b':\n",
    "                    #check for song without \"t\" or \"b\"\n",
    "                    song_id = SONGS.get(leader['song'][0:-1])\n",
    "                else:\n",
    "                    #check for song on \"top\"\n",
    "                    song_id = SONGS.get(leader['song']+'t')\n",
    "                SONGS[leader['song']] = song_id # memoize this result\n",
    "            if not song_id:\n",
    "                print(leader)\n",
    "                print(\"\\tno song id! %s\"%(leader['song']))\n",
    "                continue\n",
    "\n",
    "            #find leader by name if exists, create if not\n",
    "            name = leader['name']\n",
    "\n",
    "            if name in INVALID:\n",
    "                if debug_print: print(\"invalid name! %s\" % (name))\n",
    "                continue\n",
    "\n",
    "            real_name = ALIASES.get(name)\n",
    "            if real_name:\n",
    "                if debug_print: print(\"replacing %s with %s\" % (name, real_name))\n",
    "                name = real_name\n",
    "\n",
    "            if name == '?':\n",
    "                # marked as a \"bad\" name in the alias table so let's just ignore this altogether\n",
    "                continue\n",
    "\n",
    "            leader_id = LEADERS.get(name)\n",
    "            if not leader_id:\n",
    "                curs.execute(\"INSERT INTO leaders (name) VALUES (?)\", [name])\n",
    "                leader_id = curs.lastrowid\n",
    "                curs.execute(\"UPDATE leader_name_aliases SET leader_id=? WHERE name=?\", [leader_id, name])\n",
    "                LEADERS[name] = leader_id\n",
    "\n",
    "            if song_id and leader_id and minutes_id:\n",
    "                curs.execute(\"INSERT INTO song_leader_joins (song_id, leader_id, minutes_id) VALUES (?,?,?)\", (song_id, leader_id, minutes_id))\n",
    "            else:\n",
    "                print(\"problem?! %d %d %d\" % (song_id, leader_id, minutes_id))\n",
    "\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def parse_all_minutes(conn):\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    # 3928 - camp fasola 2012\n",
    "    # 3542 - ireland\n",
    "    curs.execute(\"SELECT Minutes, Name, Date, id, isDenson, isVirtual FROM minutes\")\n",
    "    rows = curs.fetchall()\n",
    "    for row in rows:\n",
    "\n",
    "        if row[4] == 0 or row[5] == 1:\n",
    "            continue\n",
    "\n",
    "        print(\"%s on %s\" % (row[1], row[2]))\n",
    "\n",
    "        s = row[0]\n",
    "        d = parse_minutes(s)\n",
    "\n",
    "        minutes_id = row[3]\n",
    "        insert_minutes(conn, d, minutes_id)\n",
    "\n",
    "    conn.commit()\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def parse_minutes_by_id(conn, minutes_id):\n",
    "    curs = conn.cursor()\n",
    "\n",
    "    # 3928 - camp fasola 2012\n",
    "    # 3542 - ireland\n",
    "    curs.execute(\"SELECT Minutes, Name, Date, id, isDenson FROM minutes WHERE id=?\", [minutes_id])\n",
    "    rows = curs.fetchall()\n",
    "    for row in rows:\n",
    "\n",
    "        if row[4] == 0:\n",
    "            continue\n",
    "\n",
    "        print(\"%s on %s\"%(row[1],row[2]))\n",
    "\n",
    "        s = row[0]\n",
    "        d = parse_minutes(s)\n",
    "\n",
    "        minutes_id = row[3]\n",
    "        insert_minutes(conn, d, minutes_id)\n",
    "        conn.commit()\n",
    "\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "def clear_minutes(conn):\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"DELETE FROM leaders\")\n",
    "    curs.execute(\"DELETE FROM song_leader_joins\")\n",
    "    curs.execute(\"DELETE FROM sqlite_sequence WHERE name='leaders'\")\n",
    "    curs.execute(\"DELETE FROM sqlite_sequence WHERE name='song_leader_joins'\")\n",
    "    conn.commit()\n",
    "    curs.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = util.open_db()\n",
    "    clear_minutes(db)\n",
    "    parse_all_minutes(db)\n",
    "    pd.DataFrame({\"Name Words\": sorted(list(cached_name_words))}).to_csv(\"spacy_names.csv\", index=False)\n",
    "    print(\"name count:\",len(cached_name_words))\n",
    "    pd.DataFrame({\"Non-Name Words\": sorted(list(cached_non_name_words))}).to_csv(\"spacy_non_names.csv\", index=False)\n",
    "    print(\"non name count:\",len(cached_non_name_words))\n",
    "    shared_values = cached_name_words & cached_non_name_words  # Intersection of sets\n",
    "    pd.DataFrame({\"Unclear Words\": list(shared_values)}).to_csv(\"spacy_shared_unclear_names.csv\", index=False)\n",
    "    pd.DataFrame({\"Multi-Name Words\": sorted(list(multi_name_words))}).to_csv(\"spacy_multi_names.csv\", index=False)\n",
    "    print(\"multi name count:\",len(multi_name_words))\n",
    "\n",
    "\n",
    "    # parse_minutes_by_id(db, 5165)\n",
    "    db.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
